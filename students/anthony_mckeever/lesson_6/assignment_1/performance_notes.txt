Advanced Programming In Python - Lesson 6 Assignment 1: Performance
RedMine Issue - SchoolOps-16
Code Poet: Anthony McKeever
Start Date: 01/01/2019
End Date: 01/02/2019

Performance Sampling Note:
    All performance sampling is done using an Ubuntu 18.04.2 LTS installation on the Windows Subsystem for Linux (WSL).
        See below for PC specs.
    All sampling is done by running the command `time python <file>` five times and averaging the times.

Testing PC Specs:
    OS: Windows 10 Pro 64-Bit (Version 1903, Build 18362.535), Ubuntu 18.04.2 LTS (WSL)
    Python Versions:
        Windows 10: Python 3.7.2 (tags/v3.7.2:9a3ffc0492, Dec 23 2018, 23:09:28)
        Ubuntu (WSL): Python 3.6.7 (default, Oct 22 2018, 11:32:17)
    Processor: Intel Core i7-4770K 3.5GHz (Overclock to 4.2Ghz with Turbo Boost enabled)
    RAM: 32 GB 1333Mhz DDR3 (4 x 8GB)


Performance Sampling Phase 1 (poor_perf.py):

Application Output:
    {'2013': 36275, '2014': 36359, '2015': 36369, '2016': 36597, '2017': 73521, '2018': 0}
    'ao' was found 100121 times

      |  Run 1:    |  Run 2:    |  Run 3:    |  Run 4:    |  Run 5:
real  |  0m2.910s  |  0m2.938s  |  0m2.945s  |  0m2.867s  |  0m3.000s
user  |  0m2.438s  |  0m2.594s  |  0m2.547s  |  0m2.469s  |  0m2.719s
sys   |  0m0.469s  |  0m0.328s  |  0m0.391s  |  0m0.406s  |  0m0.266s

Avg. Real:  2.932   seconds
Avg. User:  2.5534  seconds
Avg. Sys:   0.372   seconds

Initial Assumptions:
    The code contains two open statements which both open the same file and reads data.  Inside tbe open statements there are
    three total for loops which go through every single line of data.  Although this may appear performant with smaller data
    sets and hardier hardware, the over all performance would degrade on larger data sets and/or light weight hardware.

    A bug exists in the code as well:
        All records for 2018 are summed into 2017.

Initial Proposal:
    1. Reduce the amount of open calls from two to one, holding the data in memory while analyizing it for the criteria in the app.
    2. Reduce the number of for loops from three to one, performing the calculations inside the single for loop.
    3. Fix bug on line 46 that sums all 2018 records into 2017.


Result:

Performance Sampling Phase 2 (good_perf.py - first revsion):

Application Output:
    {'2013': 36275, '2014': 36359, '2015': 36369, '2016': 36597, '2017': 36998, '2018': 36523}
    'ao' was found 100121 times

      |  Run 1:    |  Run 2:    |  Run 3:    |  Run 4:    |  Run 5:
real  |  0m1.101s  |  0m1.102s  |  0m1.108s  |  0m1.117s  |  0m1.093s
user  |  0m1.031s  |  0m1.016s  |  0m1.016s  |  0m1.063s  |  0m1.047s
sys   |  0m0.078s  |  0m0.063s  |  0m0.078s  |  0m0.047s  |  0m0.031s

Avg. Real:  1.1042  seconds     -   Improvement:    1.8278  seconds
Avg. User:  1.0346  seconds     -   Improvement:    1.5188  seconds
Avg. Sys:   0.0594  seconds     -   Improvement:    0.3126  seconds

Result Notes:
    The improvement in performance with the changes recommended in the initial proposal reduced the run time for 1,000,000 records
    by appoximately 1.83 seconds.  This performance increase will help the run time on less hardier equipment going forward.

